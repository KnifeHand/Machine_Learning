import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn import linear_model, datasets
from sklearn.preprocessing import PolynomialFeatures


m = 500
np.random.seed(seed=5)
X = 6 * np.random.random(m).reshape(-1, 1) - 3
y = 0.5 * X ** 5 - X ** 3 - X ** 2 + 2 + 5 * np.random.randn(m, 1)

X_train = X[:-300]
X_test = X[-200:]
Y_train = y[:-300]
Y_test = y[-200:]

lr = LinearRegression()  # linear regression
pr = LinearRegression()  # poly regression
quadratic = PolynomialFeatures(degree=2)
X_quad = quadratic.fit_transform(X)

# Comparison model
lr.fit(X, y)
X_fit = np.arange(250,600,10)[:, np.newaxis]
y_lin_fit = lr.predict(X_fit)
regression = linear_model.LinearRegression()
regression.fit(X, y)
print('Slope: %.3f' % regression.coef_[0])
var = regression.intercept_, regression.coef_
predict = regression.predict(X_test)
print("SKLearn"), print(predict, "\n")

#Fit  mult regr model on the transformed features for polynomial reg
pr.fit(X_quad, y)
y_quad_fit = pr.predict(quadratic.fit_transform(X_fit))

print(f"mean_squared_error = {mean_squared_error(Y_train, predict)}")

#Plotting the results
plt.scatter(X, y, label='training points')
plt.plot(X_fit, y_lin_fit, label='linear fit', linestyle='--')
plt.plot(X_fit, y_quad_fit, label='quadratic fit')
plt.legend(loc='upper left')
plt.scatter(X_test, Y_test, c='pink')
plt.plot(X_test, predict)
plt.xticks(())
plt.yticks(())
plt.show()

# Polynomial 
results = []
degrees = [(2, 'red'), (5, 'orange'), (8, 'yellow')]  # , (10, 'green'), (20, 'blue')
for _degree, clr in degrees:
  polynomial_features = PolynomialFeatures(degree=_degree, include_bias=False)
  X_polynomial = polynomial_features.fit_transform(X_train)
  X_polynomial_test = polynomial_features.fit_transform(X_test)
  X_Polynomial = regression
  X_Polynomial.fit(X_polynomial, Y_train)
  results.append((regression.intercept_, regression.coef_))
  plt.scatter(X_test, Y_test,  color=clr)
  plt.plot(X_test, predict, color='blue', linewidth=3)
  plt.plot(X_test, predict, color='blue', linewidth=3)
plt.show()

y_lin_pred = lr.predict(X)
y_quad_pred = pr.predict(X_quad)

print('Training MSE linear: %.3f, quadratic: %.3f' % 
      (mean_squared_error(y, y_lin_pred), 
       mean_squared_error(y, y_quad_pred)))

print('Training R^2 linear: %.3f, quadratic: %.3f' % 
      (r2_score(y, y_lin_pred), r2_score(y,y_quad_pred)))

#   plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')
# plt.plot(diabetes_X_test, diabetes_y_pred2, color='red', linewidth=3)

for i in results:
  intercept, coefficient = i
  print(f'intercept={intercept}, coefficients={coefficient}')


# plt.scatter(X_test, Y_test, c='pink')
# plt.plot(X_test, predict)
# plt.xticks(())
# plt.yticks(())
# plt.show()
print('Coefficient of determination: %.2f' % r2_score(Y_test, predict))
plt.show()
plt.scatter(X_test, Y_test,  color='green')
plt.xticks(())
plt.yticks(())
plt.show()